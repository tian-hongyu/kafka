2019-06-13 16:11:44,493 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:312] - DEBUG: Starting the Kafka producer
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-closed
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-created
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name select-time
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name io-time
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1210] - WARNING: socket.inet_pton not available on this platform. consider `pip install win_inet_pton`
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:224] - INFO: Bootstrapping cluster metadata from [('localhost', 9092, 0)]
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:241] - DEBUG: Attempting to bootstrap via node at localhost:9092
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent-received
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-received
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name request-latency
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-sent
2019-06-13 16:11:44,509 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-received
2019-06-13 16:11:44,510 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.latency
2019-06-13 16:11:44,510 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/localhost port=9092>: creating new socket
2019-06-13 16:11:44,515 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:11:44,515 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: connecting to ::1:9092
2019-06-13 16:11:44,516 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:331] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: established TCP connection
2019-06-13 16:11:44,516 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:340] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Connection complete.
2019-06-13 16:11:44,516 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node bootstrap connected
2019-06-13 16:11:44,516 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Request 1: MetadataRequest_v0(topics=[])
2019-06-13 16:11:44,519 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Response 1: MetadataResponse_v0(brokers=[(node_id=0, host=u'yuan-PC', port=9092)], topics=[(error_code=0, topic=u'dns', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])]), (error_code=0, topic=u'__consumer_offsets', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=10, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=20, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=40, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=30, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=9, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=11, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=31, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=39, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=13, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=18, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=22, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=8, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=32, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=43, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=29, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=34, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=1, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=6, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=41, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=27, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=48, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=5, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=15, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=35, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=25, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=46, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=26, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=36, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=44, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=16, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=37, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=17, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=45, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=3, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=24, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=38, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=33, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=23, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=28, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=2, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=12, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=19, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=14, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=4, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=47, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=49, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=42, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=7, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=21, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:11:44,519 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 2, groups: 0)
2019-06-13 16:11:44,519 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:263] - INFO: Bootstrap succeeded: found 1 brokers and 2 topics.
2019-06-13 16:11:44,519 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Closing connection. 
2019-06-13 16:11:44,519 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: reconnect backoff 0.0525849544773 after 1 failures
2019-06-13 16:11:44,525 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:346] - DEBUG: Initiating connection to node 0 at yuan-PC:9092
2019-06-13 16:11:44,526 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-sent
2019-06-13 16:11:44,526 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-received
2019-06-13 16:11:44,526 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.latency
2019-06-13 16:11:44,526 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/yuan-PC port=9092>: creating new socket
2019-06-13 16:11:44,532 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:11:44,532 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: connecting to fe80::e5b1:a9aa:4a9d:b6b0%11:9092
2019-06-13 16:11:44,532 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node 0 connected
2019-06-13 16:11:44,640 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1006] - INFO: Broker version identifed as 0.11.0
2019-06-13 16:11:44,640 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1008] - INFO: Set configuration api_version=(0, 11, 0) to skip auto check_version requests on startup
2019-06-13 16:11:44,641 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bufferpool-wait-time
2019-06-13 16:11:44,641 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name batch-size
2019-06-13 16:11:44,642 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name compression-rate
2019-06-13 16:11:44,642 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name queue-time
2019-06-13 16:11:44,642 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name produce-throttle-time
2019-06-13 16:11:44,642 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name records-per-request
2019-06-13 16:11:44,642 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes
2019-06-13 16:11:44,642 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-retries
2019-06-13 16:11:44,644 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name errors
2019-06-13 16:11:44,644 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-size-max
2019-06-13 16:11:44,644 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:55] - DEBUG: Starting Kafka producer I/O thread.
2019-06-13 16:11:44,644 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:370] - DEBUG: Kafka producer started
2019-06-13 16:11:44,645 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:525] - DEBUG: Sending (key=None value='{"L7_PROTO": "5.126", "PROTOCOL": 17, "DOWNSTREAM_TUNNEL_ID": 1, "L4_SRC_PORT": 61104, "IPV4_SRC_ADDR": "192.168.0.2", "IPV4_DST_ADDR": "218.30.118.6", "DNS_QUERY": "stats.g.doubleclick.net", "HTTP_URL": "192.168.10.79", "L4_DST_PORT": 53}') to TopicPartition(topic='dns', partition=0)
2019-06-13 16:11:44,647 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:246] - DEBUG: Allocating a new 16384 byte message buffer for TopicPartition(topic='dns', partition=0)
2019-06-13 16:11:44,647 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:745] - DEBUG: Sending metadata request MetadataRequest_v1(topics=['dns']) to node 0
2019-06-13 16:11:44,648 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:532] - DEBUG: Waking up the sender since TopicPartition(topic='dns', partition=0) is either full or getting a new batch
2019-06-13 16:11:44,648 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 3: MetadataRequest_v1(topics=['dns'])
2019-06-13 16:11:44,648 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:574] - DEBUG: Flushing accumulated records in producer.
2019-06-13 16:11:44,648 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:528] - DEBUG: Waiting on produce to TopicPartition(topic='dns', partition=0)
2019-06-13 16:11:44,650 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:109] - DEBUG: Node 0 not ready; delaying produce of accumulated batch
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 3: MetadataResponse_v1(brokers=[(node_id=0, host=u'yuan-PC', port=9092, rack=None)], controller_id=0, topics=[(error_code=0, topic=u'dns', is_internal=False, partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, groups: 0)
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.records-per-batch
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.bytes
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.compression-rate
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-retries
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-errors
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:140] - DEBUG: Nodes with data ready to send: set([0])
2019-06-13 16:11:44,651 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:141] - DEBUG: Created 1 produce requests: {0: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])}
2019-06-13 16:11:44,653 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:146] - DEBUG: Sending Produce Request: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])
2019-06-13 16:11:44,653 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 4: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(0, <_io.BytesIO object at 0x00000000034903B8>)])])
2019-06-13 16:11:44,815 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 4: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=30, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:11:44,816 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:190] - DEBUG: Parsing produce response: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=30, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:11:44,816 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:77] - DEBUG: Produced messages to topic-partition TopicPartition(topic='dns', partition=0) with base offset 30 and error None.
2019-06-13 16:11:44,819 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:423] - INFO: Closing the Kafka producer with 0 secs timeout.
2019-06-13 16:11:44,819 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:443] - INFO: Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2019-06-13 16:11:44,819 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:64] - DEBUG: Beginning shutdown of Kafka producer I/O thread, sending remaining records.
2019-06-13 16:11:44,819 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: Closing connection. 
2019-06-13 16:11:44,821 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: reconnect backoff 0.0450467439713 after 1 failures
2019-06-13 16:11:44,821 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:88] - DEBUG: Shutdown of Kafka producer I/O thread has completed.
2019-06-13 16:11:44,821 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:459] - DEBUG: The Kafka producer has closed.
2019-06-13 16:11:44,828 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:413] - INFO: Kafka producer closed
2019-06-13 16:12:53,039 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:312] - DEBUG: Starting the Kafka producer
2019-06-13 16:12:53,040 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-closed
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-created
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name select-time
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name io-time
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1210] - WARNING: socket.inet_pton not available on this platform. consider `pip install win_inet_pton`
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:224] - INFO: Bootstrapping cluster metadata from [('localhost', 9092, 0)]
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:241] - DEBUG: Attempting to bootstrap via node at localhost:9092
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent-received
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-received
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name request-latency
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-sent
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-received
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.latency
2019-06-13 16:12:53,042 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/localhost port=9092>: creating new socket
2019-06-13 16:12:53,053 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:12:53,053 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: connecting to ::1:9092
2019-06-13 16:12:53,055 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:331] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: established TCP connection
2019-06-13 16:12:53,055 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:340] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Connection complete.
2019-06-13 16:12:53,055 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node bootstrap connected
2019-06-13 16:12:53,055 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Request 1: MetadataRequest_v0(topics=[])
2019-06-13 16:12:53,056 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Response 1: MetadataResponse_v0(brokers=[(node_id=0, host=u'yuan-PC', port=9092)], topics=[(error_code=0, topic=u'dns', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])]), (error_code=0, topic=u'__consumer_offsets', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=10, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=20, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=40, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=30, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=9, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=11, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=31, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=39, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=13, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=18, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=22, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=8, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=32, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=43, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=29, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=34, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=1, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=6, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=41, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=27, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=48, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=5, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=15, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=35, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=25, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=46, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=26, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=36, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=44, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=16, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=37, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=17, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=45, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=3, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=24, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=38, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=33, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=23, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=28, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=2, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=12, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=19, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=14, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=4, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=47, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=49, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=42, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=7, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=21, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:12:53,058 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 2, groups: 0)
2019-06-13 16:12:53,058 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:263] - INFO: Bootstrap succeeded: found 1 brokers and 2 topics.
2019-06-13 16:12:53,058 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Closing connection. 
2019-06-13 16:12:53,058 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: reconnect backoff 0.0569382792307 after 1 failures
2019-06-13 16:12:53,058 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:346] - DEBUG: Initiating connection to node 0 at yuan-PC:9092
2019-06-13 16:12:53,059 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-sent
2019-06-13 16:12:53,059 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-received
2019-06-13 16:12:53,059 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.latency
2019-06-13 16:12:53,059 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/yuan-PC port=9092>: creating new socket
2019-06-13 16:12:53,065 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:12:53,065 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: connecting to fe80::e5b1:a9aa:4a9d:b6b0%11:9092
2019-06-13 16:12:53,065 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node 0 connected
2019-06-13 16:12:53,174 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1006] - INFO: Broker version identifed as 0.11.0
2019-06-13 16:12:53,174 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1008] - INFO: Set configuration api_version=(0, 11, 0) to skip auto check_version requests on startup
2019-06-13 16:12:53,177 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bufferpool-wait-time
2019-06-13 16:12:53,177 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name batch-size
2019-06-13 16:12:53,178 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name compression-rate
2019-06-13 16:12:53,178 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name queue-time
2019-06-13 16:12:53,180 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name produce-throttle-time
2019-06-13 16:12:53,180 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name records-per-request
2019-06-13 16:12:53,180 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes
2019-06-13 16:12:53,180 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-retries
2019-06-13 16:12:53,180 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name errors
2019-06-13 16:12:53,181 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-size-max
2019-06-13 16:12:53,183 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:55] - DEBUG: Starting Kafka producer I/O thread.
2019-06-13 16:12:53,183 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:370] - DEBUG: Kafka producer started
2019-06-13 16:12:53,186 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:525] - DEBUG: Sending (key=None value='{"L7_PROTO": "5.126", "PROTOCOL": 17, "DOWNSTREAM_TUNNEL_ID": 1, "L4_SRC_PORT": 61104, "IPV4_SRC_ADDR": "192.168.0.2", "IPV4_DST_ADDR": "218.30.118.6", "DNS_QUERY": "stats.g.doubleclick.net", "HTTP_URL": "192.168.10.79", "L4_DST_PORT": 53}') to TopicPartition(topic='dns', partition=0)
2019-06-13 16:12:53,187 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:246] - DEBUG: Allocating a new 16384 byte message buffer for TopicPartition(topic='dns', partition=0)
2019-06-13 16:12:53,187 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:745] - DEBUG: Sending metadata request MetadataRequest_v1(topics=['dns']) to node 0
2019-06-13 16:12:53,190 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:532] - DEBUG: Waking up the sender since TopicPartition(topic='dns', partition=0) is either full or getting a new batch
2019-06-13 16:12:53,190 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 3: MetadataRequest_v1(topics=['dns'])
2019-06-13 16:12:53,191 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:574] - DEBUG: Flushing accumulated records in producer.
2019-06-13 16:12:53,191 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:528] - DEBUG: Waiting on produce to TopicPartition(topic='dns', partition=0)
2019-06-13 16:12:53,191 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:109] - DEBUG: Node 0 not ready; delaying produce of accumulated batch
2019-06-13 16:12:53,193 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 3: MetadataResponse_v1(brokers=[(node_id=0, host=u'yuan-PC', port=9092, rack=None)], controller_id=0, topics=[(error_code=0, topic=u'dns', is_internal=False, partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:12:53,193 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, groups: 0)
2019-06-13 16:12:53,193 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.records-per-batch
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.bytes
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.compression-rate
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-retries
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-errors
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:140] - DEBUG: Nodes with data ready to send: set([0])
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:141] - DEBUG: Created 1 produce requests: {0: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])}
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:146] - DEBUG: Sending Produce Request: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])
2019-06-13 16:12:53,194 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 4: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(0, <_io.BytesIO object at 0x00000000034403B8>)])])
2019-06-13 16:12:53,197 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 4: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=31, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:12:53,197 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:190] - DEBUG: Parsing produce response: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=31, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:12:53,197 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:77] - DEBUG: Produced messages to topic-partition TopicPartition(topic='dns', partition=0) with base offset 31 and error None.
2019-06-13 16:12:53,198 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:423] - INFO: Closing the Kafka producer with 0 secs timeout.
2019-06-13 16:12:53,198 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:443] - INFO: Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2019-06-13 16:12:53,198 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:64] - DEBUG: Beginning shutdown of Kafka producer I/O thread, sending remaining records.
2019-06-13 16:12:53,198 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: Closing connection. 
2019-06-13 16:12:53,200 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: reconnect backoff 0.0565102273594 after 1 failures
2019-06-13 16:12:53,200 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:88] - DEBUG: Shutdown of Kafka producer I/O thread has completed.
2019-06-13 16:12:53,200 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:459] - DEBUG: The Kafka producer has closed.
2019-06-13 16:12:53,210 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:413] - INFO: Kafka producer closed
2019-06-13 16:13:20,101 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:312] - DEBUG: Starting the Kafka producer
2019-06-13 16:13:20,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-closed
2019-06-13 16:13:20,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-created
2019-06-13 16:13:20,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name select-time
2019-06-13 16:13:20,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name io-time
2019-06-13 16:13:20,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1210] - WARNING: socket.inet_pton not available on this platform. consider `pip install win_inet_pton`
2019-06-13 16:13:20,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:224] - INFO: Bootstrapping cluster metadata from [('localhost', 9092, 0)]
2019-06-13 16:13:20,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:241] - DEBUG: Attempting to bootstrap via node at localhost:9092
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent-received
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-received
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name request-latency
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-sent
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-received
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.latency
2019-06-13 16:13:20,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/localhost port=9092>: creating new socket
2019-06-13 16:13:20,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:13:20,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: connecting to ::1:9092
2019-06-13 16:13:20,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:331] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: established TCP connection
2019-06-13 16:13:20,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:340] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Connection complete.
2019-06-13 16:13:20,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node bootstrap connected
2019-06-13 16:13:20,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Request 1: MetadataRequest_v0(topics=[])
2019-06-13 16:13:20,114 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Response 1: MetadataResponse_v0(brokers=[(node_id=0, host=u'yuan-PC', port=9092)], topics=[(error_code=0, topic=u'dns', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])]), (error_code=0, topic=u'__consumer_offsets', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=10, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=20, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=40, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=30, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=9, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=11, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=31, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=39, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=13, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=18, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=22, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=8, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=32, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=43, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=29, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=34, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=1, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=6, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=41, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=27, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=48, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=5, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=15, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=35, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=25, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=46, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=26, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=36, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=44, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=16, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=37, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=17, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=45, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=3, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=24, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=38, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=33, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=23, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=28, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=2, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=12, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=19, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=14, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=4, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=47, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=49, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=42, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=7, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=21, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:13:20,115 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 2, groups: 0)
2019-06-13 16:13:20,115 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:263] - INFO: Bootstrap succeeded: found 1 brokers and 2 topics.
2019-06-13 16:13:20,115 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Closing connection. 
2019-06-13 16:13:20,115 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: reconnect backoff 0.0531748998259 after 1 failures
2019-06-13 16:13:20,115 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:346] - DEBUG: Initiating connection to node 0 at yuan-PC:9092
2019-06-13 16:13:20,117 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-sent
2019-06-13 16:13:20,117 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-received
2019-06-13 16:13:20,117 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.latency
2019-06-13 16:13:20,117 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/yuan-PC port=9092>: creating new socket
2019-06-13 16:13:20,122 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:13:20,122 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: connecting to fe80::e5b1:a9aa:4a9d:b6b0%11:9092
2019-06-13 16:13:20,124 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node 0 connected
2019-06-13 16:13:20,230 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1006] - INFO: Broker version identifed as 0.11.0
2019-06-13 16:13:20,230 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1008] - INFO: Set configuration api_version=(0, 11, 0) to skip auto check_version requests on startup
2019-06-13 16:13:20,233 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bufferpool-wait-time
2019-06-13 16:13:20,233 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name batch-size
2019-06-13 16:13:20,234 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name compression-rate
2019-06-13 16:13:20,234 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name queue-time
2019-06-13 16:13:20,236 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name produce-throttle-time
2019-06-13 16:13:20,236 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name records-per-request
2019-06-13 16:13:20,236 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes
2019-06-13 16:13:20,236 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-retries
2019-06-13 16:13:20,236 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name errors
2019-06-13 16:13:20,237 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-size-max
2019-06-13 16:13:20,239 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:55] - DEBUG: Starting Kafka producer I/O thread.
2019-06-13 16:13:20,239 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:370] - DEBUG: Kafka producer started
2019-06-13 16:13:20,240 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:525] - DEBUG: Sending (key=None value='{"L7_PROTO": "5.126", "PROTOCOL": 17, "DOWNSTREAM_TUNNEL_ID": 1, "L4_SRC_PORT": 61104, "IPV4_SRC_ADDR": "192.168.0.2", "IPV4_DST_ADDR": "218.30.118.6", "DNS_QUERY": "stats.g.doubleclick.net", "HTTP_URL": "192.168.10.79", "L4_DST_PORT": 53}') to TopicPartition(topic='dns', partition=0)
2019-06-13 16:13:20,243 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:246] - DEBUG: Allocating a new 16384 byte message buffer for TopicPartition(topic='dns', partition=0)
2019-06-13 16:13:20,243 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:745] - DEBUG: Sending metadata request MetadataRequest_v1(topics=['dns']) to node 0
2019-06-13 16:13:20,244 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:532] - DEBUG: Waking up the sender since TopicPartition(topic='dns', partition=0) is either full or getting a new batch
2019-06-13 16:13:20,246 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 3: MetadataRequest_v1(topics=['dns'])
2019-06-13 16:13:20,247 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:574] - DEBUG: Flushing accumulated records in producer.
2019-06-13 16:13:20,249 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:528] - DEBUG: Waiting on produce to TopicPartition(topic='dns', partition=0)
2019-06-13 16:13:20,250 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 3: MetadataResponse_v1(brokers=[(node_id=0, host=u'yuan-PC', port=9092, rack=None)], controller_id=0, topics=[(error_code=0, topic=u'dns', is_internal=False, partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:13:20,252 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, groups: 0)
2019-06-13 16:13:20,252 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.records-per-batch
2019-06-13 16:13:20,253 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.bytes
2019-06-13 16:13:20,253 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.compression-rate
2019-06-13 16:13:20,253 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-retries
2019-06-13 16:13:20,253 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-errors
2019-06-13 16:13:20,253 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:140] - DEBUG: Nodes with data ready to send: set([0])
2019-06-13 16:13:20,253 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:141] - DEBUG: Created 1 produce requests: {0: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])}
2019-06-13 16:13:20,253 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:146] - DEBUG: Sending Produce Request: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])
2019-06-13 16:13:20,255 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 4: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(0, <_io.BytesIO object at 0x00000000034403B8>)])])
2019-06-13 16:13:20,259 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 4: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=32, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:13:20,259 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:190] - DEBUG: Parsing produce response: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=32, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:13:20,259 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:77] - DEBUG: Produced messages to topic-partition TopicPartition(topic='dns', partition=0) with base offset 32 and error None.
2019-06-13 16:13:20,260 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:423] - INFO: Closing the Kafka producer with 0 secs timeout.
2019-06-13 16:13:20,262 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:443] - INFO: Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2019-06-13 16:13:20,263 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:64] - DEBUG: Beginning shutdown of Kafka producer I/O thread, sending remaining records.
2019-06-13 16:13:20,263 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: Closing connection. 
2019-06-13 16:13:20,263 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: reconnect backoff 0.0436199554456 after 1 failures
2019-06-13 16:13:20,263 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:88] - DEBUG: Shutdown of Kafka producer I/O thread has completed.
2019-06-13 16:13:20,263 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:459] - DEBUG: The Kafka producer has closed.
2019-06-13 16:13:20,275 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:413] - INFO: Kafka producer closed
2019-06-13 16:14:25,966 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:312] - DEBUG: Starting the Kafka producer
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-closed
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name connections-created
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name select-time
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name io-time
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1210] - WARNING: socket.inet_pton not available on this platform. consider `pip install win_inet_pton`
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:224] - INFO: Bootstrapping cluster metadata from [('localhost', 9092, 0)]
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:241] - DEBUG: Attempting to bootstrap via node at localhost:9092
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent-received
2019-06-13 16:14:25,967 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-sent
2019-06-13 16:14:25,969 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes-received
2019-06-13 16:14:25,969 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name request-latency
2019-06-13 16:14:25,969 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-sent
2019-06-13 16:14:25,969 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.bytes-received
2019-06-13 16:14:25,969 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-bootstrap.latency
2019-06-13 16:14:25,969 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/localhost port=9092>: creating new socket
2019-06-13 16:14:25,973 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:14:25,973 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: connecting to ::1:9092
2019-06-13 16:14:25,973 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:331] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: established TCP connection
2019-06-13 16:14:25,973 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:340] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Connection complete.
2019-06-13 16:14:25,973 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node bootstrap connected
2019-06-13 16:14:25,974 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Request 1: MetadataRequest_v0(topics=[])
2019-06-13 16:14:25,976 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092> Response 1: MetadataResponse_v0(brokers=[(node_id=0, host=u'yuan-PC', port=9092)], topics=[(error_code=0, topic=u'dns', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])]), (error_code=0, topic=u'__consumer_offsets', partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=10, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=20, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=40, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=30, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=9, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=11, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=31, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=39, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=13, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=18, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=22, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=8, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=32, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=43, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=29, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=34, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=1, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=6, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=41, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=27, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=48, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=5, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=15, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=35, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=25, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=46, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=26, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=36, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=44, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=16, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=37, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=17, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=45, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=3, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=24, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=38, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=33, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=23, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=28, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=2, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=12, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=19, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=14, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=4, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=47, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=49, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=42, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=7, leader=0, replicas=[0], isr=[0]), (error_code=0, partition=21, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:14:25,976 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 2, groups: 0)
2019-06-13 16:14:25,977 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:263] - INFO: Bootstrap succeeded: found 1 brokers and 2 topics.
2019-06-13 16:14:25,977 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: Closing connection. 
2019-06-13 16:14:25,977 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=bootstrap host=localhost/::1 port=9092>: reconnect backoff 0.0579417550568 after 1 failures
2019-06-13 16:14:25,977 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:346] - DEBUG: Initiating connection to node 0 at yuan-PC:9092
2019-06-13 16:14:25,979 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-sent
2019-06-13 16:14:25,979 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.bytes-received
2019-06-13 16:14:25,979 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name node-0.latency
2019-06-13 16:14:25,979 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:257] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/yuan-PC port=9092>: creating new socket
2019-06-13 16:14:25,986 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:303] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: setting socket option (6, 1, 1)
2019-06-13 16:14:25,986 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:309] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: connecting to fe80::e5b1:a9aa:4a9d:b6b0%11:9092
2019-06-13 16:14:25,986 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:296] - DEBUG: Node 0 connected
2019-06-13 16:14:26,089 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1006] - INFO: Broker version identifed as 0.11.0
2019-06-13 16:14:26,091 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:1008] - INFO: Set configuration api_version=(0, 11, 0) to skip auto check_version requests on startup
2019-06-13 16:14:26,092 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bufferpool-wait-time
2019-06-13 16:14:26,092 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name batch-size
2019-06-13 16:14:26,092 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name compression-rate
2019-06-13 16:14:26,092 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name queue-time
2019-06-13 16:14:26,092 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name produce-throttle-time
2019-06-13 16:14:26,094 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name records-per-request
2019-06-13 16:14:26,094 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name bytes
2019-06-13 16:14:26,094 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-retries
2019-06-13 16:14:26,095 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name errors
2019-06-13 16:14:26,095 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name record-size-max
2019-06-13 16:14:26,095 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:55] - DEBUG: Starting Kafka producer I/O thread.
2019-06-13 16:14:26,095 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:370] - DEBUG: Kafka producer started
2019-06-13 16:14:26,098 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:525] - DEBUG: Sending (key=None value='{"L7_PROTO": "5.126", "PROTOCOL": 17, "DOWNSTREAM_TUNNEL_ID": 1, "L4_SRC_PORT": 61104, "IPV4_SRC_ADDR": "192.168.0.2", "IPV4_DST_ADDR": "218.30.118.6", "DNS_QUERY": "stats.g.doubleclick.net", "HTTP_URL": "192.168.10.79", "L4_DST_PORT": 53}') to TopicPartition(topic='dns', partition=0)
2019-06-13 16:14:26,098 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:246] - DEBUG: Allocating a new 16384 byte message buffer for TopicPartition(topic='dns', partition=0)
2019-06-13 16:14:26,098 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\client_async.py[line:745] - DEBUG: Sending metadata request MetadataRequest_v1(topics=['dns']) to node 0
2019-06-13 16:14:26,099 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:532] - DEBUG: Waking up the sender since TopicPartition(topic='dns', partition=0) is either full or getting a new batch
2019-06-13 16:14:26,101 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 3: MetadataRequest_v1(topics=['dns'])
2019-06-13 16:14:26,101 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:574] - DEBUG: Flushing accumulated records in producer.
2019-06-13 16:14:26,101 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:528] - DEBUG: Waiting on produce to TopicPartition(topic='dns', partition=0)
2019-06-13 16:14:26,102 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 3: MetadataResponse_v1(brokers=[(node_id=0, host=u'yuan-PC', port=9092, rack=None)], controller_id=0, topics=[(error_code=0, topic=u'dns', is_internal=False, partitions=[(error_code=0, partition=0, leader=0, replicas=[0], isr=[0])])])
2019-06-13 16:14:26,102 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\cluster.py[line:289] - DEBUG: Updated cluster metadata to ClusterMetadata(brokers: 1, topics: 1, groups: 0)
2019-06-13 16:14:26,102 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.records-per-batch
2019-06-13 16:14:26,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.bytes
2019-06-13 16:14:26,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.compression-rate
2019-06-13 16:14:26,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-retries
2019-06-13 16:14:26,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\metrics\metrics.py[line:156] - DEBUG: Added sensor with name topic.dns.record-errors
2019-06-13 16:14:26,104 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:140] - DEBUG: Nodes with data ready to send: set([0])
2019-06-13 16:14:26,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:141] - DEBUG: Created 1 produce requests: {0: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])}
2019-06-13 16:14:26,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:146] - DEBUG: Sending Produce Request: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(partition=0, messages=['(offset=0, message=261)'])])])
2019-06-13 16:14:26,105 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:693] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Request 4: ProduceRequest_v2(required_acks=1, timeout=30000, topics=[(topic='dns', partitions=[(0, <_io.BytesIO object at 0x00000000033803B8>)])])
2019-06-13 16:14:26,108 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:875] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092> Response 4: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=33, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:14:26,108 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:190] - DEBUG: Parsing produce response: ProduceResponse_v2(topics=[(topic=u'dns', partitions=[(partition=0, error_code=0, offset=33, timestamp=-1)])], throttle_time_ms=0)
2019-06-13 16:14:26,109 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\record_accumulator.py[line:77] - DEBUG: Produced messages to topic-partition TopicPartition(topic='dns', partition=0) with base offset 33 and error None.
2019-06-13 16:14:26,109 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:423] - INFO: Closing the Kafka producer with 0 secs timeout.
2019-06-13 16:14:26,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:443] - INFO: Proceeding to force close the producer since pending requests could not be completed within timeout 0.
2019-06-13 16:14:26,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:64] - DEBUG: Beginning shutdown of Kafka producer I/O thread, sending remaining records.
2019-06-13 16:14:26,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:628] - INFO: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: Closing connection. 
2019-06-13 16:14:26,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\conn.py[line:610] - DEBUG: <BrokerConnection node_id=0 host=yuan-PC/fe80::e5b1:a9aa:4a9d:b6b0%11 port=9092>: reconnect backoff 0.0562217189332 after 1 failures
2019-06-13 16:14:26,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\sender.py[line:88] - DEBUG: Shutdown of Kafka producer I/O thread has completed.
2019-06-13 16:14:26,111 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:459] - DEBUG: The Kafka producer has closed.
2019-06-13 16:14:26,122 - C:\Users\yuan\Envs\py2_spiderfoot\lib\site-packages\kafka\producer\kafka.py[line:413] - INFO: Kafka producer closed
